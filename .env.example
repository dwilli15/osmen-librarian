# =============================================================================
# OsMEN Librarian - Environment Configuration
# =============================================================================
# Part of the OsMEN ecosystem: https://github.com/dwilli15/OsMEN
# Copy this file to .env and customize for your environment

# -----------------------------------------------------------------------------
# Core Configuration
# -----------------------------------------------------------------------------

# Path to knowledge base documents
LIBRARIAN_DATA_DIR=./data

# Path to ChromaDB persistence directory
LIBRARIAN_DB_PATH=./data/db

# Embedding model (default: Stella 1.5B for best quality)
# Options: dunzhang/stella_en_1.5B_v5, sentence-transformers/all-MiniLM-L6-v2
LIBRARIAN_EMBEDDING_MODEL=dunzhang/stella_en_1.5B_v5

# Device for embeddings (auto, cuda, cpu)
LIBRARIAN_DEVICE=auto

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------

# FastAPI server host and port
LIBRARIAN_HOST=0.0.0.0
LIBRARIAN_PORT=8000

# Enable/disable debug mode
LIBRARIAN_DEBUG=false

# -----------------------------------------------------------------------------
# Observability (Optional)
# -----------------------------------------------------------------------------

# LangSmith tracing (get key at https://smith.langchain.com/)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your-langsmith-api-key
# LANGCHAIN_PROJECT=osmen-librarian

# Langfuse tracing (self-hosted alternative)
# LANGFUSE_SECRET_KEY=your-langfuse-secret
# LANGFUSE_PUBLIC_KEY=your-langfuse-public
# LANGFUSE_HOST=https://cloud.langfuse.com

# -----------------------------------------------------------------------------
# LLM Configuration (Optional - for agent features)
# -----------------------------------------------------------------------------

# OpenAI API key for LLM-powered features
# OPENAI_API_KEY=your-openai-api-key

# Azure OpenAI (alternative to OpenAI)
# AZURE_OPENAI_API_KEY=your-azure-key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Local LLM (LM Studio / Ollama)
# LOCAL_LLM_URL=http://localhost:1234/v1

# -----------------------------------------------------------------------------
# OsMEN Integration (Optional)
# -----------------------------------------------------------------------------

# When used as OsMEN dependency, these settings apply
# OSMEN_AGENT_ID=librarian
# OSMEN_COORDINATOR_URL=http://localhost:8080
